# Research and implementation of energy consumption optimization algorithm for data center

The dataset used in the code of this project is *"PUE Data Summary_processed.xlsx"*, which is a preprocessed version of the original dataset *"PUE Data Summary.xlsx"*. This processed dataset is employed for prediction and optimization throughout the entire project. Specifically, the project utilizes an energy consumption prediction model based on **AdaBoost** and a temperature prediction model based on **LightGBM** together for parameter particle swarm optimization via **ALF-PSO**. The goal is to identify an optimal parameter combination that achieves lower energy consumption compared to the original parameter set. The prediction from **AdaBoost** serves as the objective function for **ALF-PSO**, while the **LightGBM** temperature prediction model imposes temperature constraints during the optimization process. If the predicted temperature value of the tuned variables exceeds the predefined limit, the parameter combination is rejected. Through continuous exploration by the **ALF-PSO** algorithm, a superior solution is ultimately found to further optimize the equipment parameters of the data center’s cooling system cluster control.

There are two main executable files:

1. **Full Dataset Prediction and Optimization**:
   - The file *"ALF_PSO_Optimize.py"* is responsible for running the prediction and optimization on the full dataset *"PUE Data Summary_processed.xlsx"*.
   - It saves the trained prediction model (*optimized_model_v2_ensemble.pkl*) and the parameter table (*optimized_meta_data_v2.json*) for later use in predicting single data entries.
   - The optimized results are exported to *"ALF_PSO_调优后的参数_v2.xlsx"*.
   - This file is then processed by *"Red_signal.py"* to highlight optimized parameters row by row, generating *"ALF-PSO__调优后的参数_v2标红.xlsx"*. This comparison between the optimized and original data marks the optimized entries in red for easier data analysis.
2. **Single Data Entry Optimization**:
   - The dataset *"测试用的一条数据.xlsx"* contains the first row as variable names and the second row as a selected data entry.
   - The file *"One_data_Optimize.py"* executes the optimization for this single data entry, exporting the results to *"单条数据优化结果.xlsx"*.
   - *"One_data_Optimize.py"* must be run after *"ALF_PSO_Optimize.py"* because it requires the metadata (*optimized_meta_data_v2.json*) and the prediction model (*optimized_model_v2_ensemble.pkl*) generated by *"ALF_PSO_Optimize.py"*.

Other Python files are intermediate analytical and procedural files, generally used for data analysis purposes.

The overall execution sequence is as follows:

1. Run *"ALF_PSO_Optimize.py"* first to save the prediction model and parameter table.
2. Then run *"One_data_Optimize.py"* to optimize single data entries.